{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "dfAuthor = pd.DataFrame()\n",
    "dfAuthor = pd.read_csv('DBPediaAuthors.csv', sep=',', low_memory=False)\n",
    "\n",
    "\n",
    "display(dfAuthor.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search DBPedia for Authors\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "\n",
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(\"\"\"\n",
    "      SELECT DISTINCT *\n",
    "      WHERE\n",
    "        {\n",
    "          ?s a dbo:Writer .\n",
    "        }\n",
    "        LIMIT 10000\n",
    "\"\"\")\n",
    "sparql.setReturnFormat(JSON)\n",
    "results = sparql.query().convert()\n",
    "\n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "import urllib3\n",
    "import urllib\n",
    "import csv\n",
    "\n",
    "import re\n",
    "\n",
    "def createMetaData( data, uriPath , dfMeta):\n",
    "    try:\n",
    "        data = json.loads(data.decode('utf-8'))\n",
    "        detailedData = data[''.join(['http://dbpedia.org/resource/', uriPath])]\n",
    "        \n",
    "        skipShortKeys = {'22-rdf-syntax-ns#type', 'rdf-schema#comment', 'thumbnail', 'wikiPageRevisionID', \n",
    "                #, 'wikiPageExternalLink', 'prov#wasDerivedFrom', 'wikiPageID', 'signature', 'bgcolor', 'quote', \n",
    "                    'imageSize', 'align', 'bgcolour', 'colwidth', 'salign', '\\'\\'\\'name\\'\\'\\'_'}\n",
    "        \n",
    "        #display(detailedData)\n",
    "        \n",
    "        for key in detailedData.keys():\n",
    "            shortKey = key.split('/')[-1]\n",
    "            if shortKey not in skipShortKeys:\n",
    "                values = []\n",
    "                values.append(key)\n",
    "                for content in detailedData[key]:\n",
    "                    if 'datatype' in content:\n",
    "                        #display(content['datatype'])\n",
    "                        values.append(content['datatype'].split('/')[-1])\n",
    "                        values.append(content['datatype'])\n",
    "                    else:\n",
    "                        values.append(\"XMLSchema#string\")\n",
    "                        values.append(\"http://www.w3.org/2001/XMLSchema#string\")\n",
    "                dfMeta[shortKey] = pd.Series(values)\n",
    "        \n",
    "        return dfMeta\n",
    "    except:\n",
    "        return dfMeta\n",
    "\n",
    "def convertResultToSeries( data, uriPath ):\n",
    "    try:   \n",
    "        data = json.loads(data.decode('utf-8'))\n",
    "        detailedData = data[''.join(['http://dbpedia.org/resource/', uriPath])]\n",
    "        #display(data)\n",
    "        author = {}\n",
    "        skipShortKeys = {'22-rdf-syntax-ns#type', 'rdf-schema#comment', 'thumbnail', 'wikiPageRevisionID', \n",
    "                #, 'wikiPageExternalLink', 'prov#wasDerivedFrom', 'wikiPageID', 'signature', 'bgcolor', 'quote', \n",
    "                    'imageSize', 'align', 'bgcolour', 'colwidth', 'salign', '\\'\\'\\'name\\'\\'\\'_'}\n",
    "        author['URI'] = ''.join(['http://dbpedia.org/resource/', uriPath])\n",
    "    \n",
    "        for key in detailedData.keys():\n",
    "            shortKey = key.split('/')[-1]\n",
    "            if shortKey not in skipShortKeys:\n",
    "                values = []\n",
    "                for content in detailedData[key]:\n",
    "                    if 'lang' in content:\n",
    "                        if 'en' in content['lang']:\n",
    "                            values.append(str(content['value']).replace('\\\\n', '').replace('http://dbpedia.org/resource/', ''))\n",
    "                    else:\n",
    "                        value = str(content['value']).replace('\\\\n', '').replace('http://dbpedia.org/resource/', '')\n",
    "                        if len(re.findall('[\\0-\\200]', value)) > 0 :\n",
    "                            values.append(value)\n",
    "                author[shortKey.lower()] = '\\t'.join(set(values))\n",
    "        return pd.DataFrame(author, index=[0])\n",
    "    \n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "\n",
    "http = urllib3.PoolManager()\n",
    "listSeries = []\n",
    "counter = 0\n",
    "\n",
    "dfAuthorMeta = pd.DataFrame()\n",
    "\n",
    "uri = []\n",
    "uri.append(\"URI\")\n",
    "uri.append(\"URI\")\n",
    "uri.append(\"http://www.w3.org/2002/07/owl#Thing\")\n",
    "dfAuthorMeta['URI'] = pd.Series(uri)\n",
    "\n",
    "for result in results[\"results\"][\"bindings\"]:\n",
    "    #if result[\"s\"][\"value\"] not in dfAuthor['identifier'].values:\n",
    "        uriPath = result[\"s\"][\"value\"].replace('http://dbpedia.org/resource/', '')\n",
    "        uriPathQuoted = urllib.parse.quote(uriPath)\n",
    "        url = \"http://dbpedia.org/data/%s.json\" % uriPathQuoted\n",
    "        r = http.request('GET', url)\n",
    "        dfAuthor = dfAuthor.append(convertResultToSeries(r.data, uriPath), ignore_index=True, sort=True)\n",
    "        dfAuthorMeta = createMetaData(r.data, uriPath, dfAuthorMeta)\n",
    "        counter = counter + 1\n",
    "        if counter > 10:\n",
    "            counter = 0\n",
    "            dfAuthorNew = dfAuthorMeta.append(dfAuthor, ignore_index=True, sort=True)\n",
    "            dfAuthorNew.to_csv('DBPediaAuthorsNew.csv', sep=',', encoding='utf-8', index=True, quotechar='\"', quoting=csv.QUOTE_ALL)\n",
    "\n",
    "dfAuthor = dfAuthorMeta.append(dfAuthor, ignore_index=True, sort=True)\n",
    "#display(dfAuthor)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "display(dfAuthor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = []\n",
    "works.append(\"http://dbpedia.org/ontology/notableWork\")\n",
    "works.append(\"XMLSchema#string\")\n",
    "works.append(\"http://www.w3.org/2001/XMLSchema#string\")\n",
    "for index, row in dfAuthor.iterrows():\n",
    "    try:\n",
    "        if(index > 2):\n",
    "            sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "            query = \"SELECT DISTINCT * WHERE { ?s dbo:author dbr:%s.} LIMIT 10000\" % row['URI'].replace('http://dbpedia.org/resource/', '')\n",
    "            sparql.setQuery(query)\n",
    "            sparql.setReturnFormat(JSON)\n",
    "            results = sparql.query().convert()\n",
    "            work_author = ''\n",
    "            for result in results[\"results\"][\"bindings\"]:\n",
    "                work_author = '\\t'.join([work_author, result[\"s\"][\"value\"].replace('http://dbpedia.org/resource/', '')])\n",
    "            works.append(work_author)\n",
    "    except:\n",
    "        display(query)\n",
    "\n",
    "dfAuthor['work'] = pd.Series(works)\n",
    "display(dfAuthor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only columns which are at least more than 15% filled\n",
    "#dfAuthorMeta = dfAuthor.describe()\n",
    "#dfAuthorMetaCount = dfAuthorMeta.loc[['count']]\n",
    "#dfAuthorMetaCount = dfAuthorMetaCount.transpose()\n",
    "#dfSelected = dfAuthorMetaCount[((dfAuthorMetaCount['count']/len(dfAuthorMetaCount)) * 100) > 15]\n",
    "#dfAuthor = dfAuthor[dfSelected.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfAuthor['notableWorks_join'] = dfAuthor['notableWork'].map(str).replace('nan', '') + dfAuthor['notableWorks'].map(str).replace('nan', '')\n",
    "#dfAuthor['notableWorks_join'] = dfAuthor['notableWorks_join'].map(str) + dfAuthor['notableWork(s)_'].map(str).replace('nan', '')\n",
    "\n",
    "#display(dfAuthor['notableWorks_join'])\n",
    "\n",
    "dfAuthor.to_csv('DBPediaAuthorsNew.csv', sep=',', encoding='utf-8', index=False, quotechar='\"', quoting=csv.QUOTE_ALL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#del dfAuthor['1a']\n",
    "#del dfAuthor['1p']\n",
    "#del dfAuthor['1pp']\n",
    "#del dfAuthor['1y']\n",
    "#del dfAuthor['2a']\n",
    "#del dfAuthor['2p']\n",
    "#del dfAuthor['2pp']\n",
    "#del dfAuthor['2ps']\n",
    "#del dfAuthor['2y']\n",
    "#del dfAuthor['3a']\n",
    "#del dfAuthor['3p']\n",
    "#del dfAuthor['3pp']\n",
    "#del dfAuthor['3y']\n",
    "#del dfAuthor['birthdate'] # birth date (lowercase) is not used (empty)\n",
    "#del dfAuthor['deathdate'] # death date (lowercase) is not used (empty)\n",
    "#display(dfAuthor)\n",
    "#dfAuthor.to_csv('DBPediaAuthors.csv', sep=',', encoding='utf-8', quotechar='\"', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "import numpy as np\n",
    "\n",
    "dfAuthorNew = pd.DataFrame()\n",
    "\n",
    "for index, row in dfAuthor.iterrows():\n",
    "    if index > 2:\n",
    "        if(isinstance(row['birthDate'], str)):\n",
    "            dates = row['birthDate'].split('\\t')\n",
    "            row['birthDate'] = dates[0]\n",
    "            if '-0-0' in row['birthDate']:\n",
    "                for date in dates:\n",
    "                    if not '-0-0' in date:\n",
    "                        row['birthDate'] = date\n",
    "            if '-0-0' in row['birthDate']:\n",
    "                row['birthDate'] = row['birthDate'].replace('-0-0', '')\n",
    "        if(isinstance(row['birthDate'], float) and np.isnan(row['birthDate'])):\n",
    "            if(isinstance(row['birth'], float) and ~np.isnan(row['birth'])):\n",
    "                row['birthDate'] = row['birth']\n",
    "            elif(isinstance(row['birthYear'], float) and ~np.isnan(row['birthYear'])):\n",
    "                row['birthDate'] = row['birthYear']\n",
    "            elif(isinstance(row['dateOfBirth'], float) and ~np.isnan(row['dateOfBirth'])):\n",
    "                row['birthDate'] = row['dateOfBirth']\n",
    "        \n",
    "        if(isinstance(row['deathDate'], str)):\n",
    "            dates = row['deathDate'].split('\\t')\n",
    "            row['deathDate'] = dates[0]\n",
    "            if '-0-0' in row['deathDate']:\n",
    "                for date in dates:\n",
    "                    if not '-0-0' in date:\n",
    "                        row['deathDate'] = date\n",
    "            if '-0-0' in row['deathDate']:\n",
    "                row['deathDate'] = row['deathDate'].replace('-0-0', '')\n",
    "                \n",
    "        if(isinstance(row['deathDate'], float) and np.isnan(row['deathDate'])):\n",
    "            if(isinstance(row['death'], float) and ~np.isnan(row['death'])):\n",
    "                row['deathDate'] = row['death']\n",
    "            elif(isinstance(row['deathYear'], float) and ~np.isnan(row['deathYear'])):\n",
    "                row['deathDate'] = row['deathYear']\n",
    "            \n",
    "    dfAuthorNew = dfAuthorNew.append(row, ignore_index=True, sort=True)\n",
    "\n",
    "del dfAuthorNew['birth']\n",
    "del dfAuthorNew['birthYear']\n",
    "del dfAuthorNew['dateOfBirth']\n",
    "del dfAuthorNew['death']\n",
    "del dfAuthorNew['deathYear']\n",
    "display(dfAuthorNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dfAuthor.to_csv('DBPediaAuthors.csv', sep=',', encoding='utf-8', index=False, quotechar='\"', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 500)\n",
    "display(dfAuthorNew)\n",
    "dfAuthorNew.to_csv('DBPediaAuthorsNew.csv', sep=',', encoding='utf-8', index=False, quotechar='\"', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n",
    "display(dfAuthor.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(dfAuthor.describe(include=\"all\"))\n",
    "dfAuthorNew = pd.DataFrame()\n",
    "listWorks = [\"notableWork\", \"notableWork(s)_\", \"notableWorks\", \"notablework\", \"notableworks\", \"work\"]\n",
    "\n",
    "for index, row in dfAuthor.iterrows():\n",
    "    if index > 2:\n",
    "        row['consolidatedWorks'] = np.nan\n",
    "        for header in listWorks:\n",
    "            if(isinstance(row[header], str)):\n",
    "                works = row[header].split('\\t')\n",
    "                for work in works:\n",
    "                    if(isinstance(row['consolidatedWorks'], str)):\n",
    "                        if work not in row['consolidatedWorks']:\n",
    "                            row['consolidatedWorks'] = row['consolidatedWorks'] + '\\t' + work\n",
    "                    else:\n",
    "                        row['consolidatedWorks'] = work\n",
    "        \n",
    "        dfAuthorNew = dfAuthorNew.append(row, ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dfAuthorNew['notableWork']\n",
    "del dfAuthorNew['notableWork(s)_']\n",
    "del dfAuthorNew['notableWorks']\n",
    "del dfAuthorNew['notablework']\n",
    "del dfAuthorNew['notableworks']\n",
    "del dfAuthorNew['work']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dfAuthorInfo = dfAuthorNew.describe(include=\"all\").transpose()\n",
    "display(dfAuthorInfo.sort_values(by=['count'], ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dfAuthorNew.to_csv('DBPediaAuthorsNew.csv', sep=',', encoding='utf-8', index=False, quotechar='\"', quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
